{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fa0ac4",
   "metadata": {},
   "source": [
    "# Assignment 6: Neural Network Showdown\n",
    "\n",
    "Build and compare neural network architectures on image and time-series data.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebeae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt\n",
    "\n",
    "# GPU acceleration (platform-specific)\n",
    "import platform\n",
    "if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "    %pip install -q tensorflow-metal\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed70f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected — using CPU\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Report available accelerators\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU acceleration: {len(gpus)} device(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  {gpu.name}\")\n",
    "else:\n",
    "    print(\"No GPU detected — using CPU\")\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import (\n",
    "    Dense, Flatten, Dropout, Conv2D, MaxPooling2D, LSTM, Input\n",
    ")\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from helpers import (\n",
    "    load_cifar10, load_ecg5000,\n",
    "    plot_training_history, plot_confusion_matrix,\n",
    "    plot_sample_images, plot_ecg_traces, plot_predictions,\n",
    "    CIFAR10_CLASSES, ECG_CLASSES,\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f79d00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Dense Baseline on CIFAR-10\n",
    "\n",
    "**Task:** Build a Dense (fully connected) network to classify CIFAR-10 images.\n",
    "\n",
    "CIFAR-10 has 60,000 color images (32x32x3) across 10 classes. A Dense network\n",
    "flattens each image into 3,072 numbers and classifies from there. This is our\n",
    "baseline — it ignores spatial structure entirely.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- Flatten the input\n",
    "- At least 2 hidden Dense layers with ReLU activation\n",
    "- Dropout after each hidden layer\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e592393b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Dense Baseline on CIFAR-10\n",
      "----------------------------------------\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1us/step\n",
      "Train: (50000, 32, 32, 3), Test: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1: Dense Baseline on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load data (normalized to [0,1], one-hot encoded)\n",
    "X_train, y_train, X_test, y_test = load_cifar10()\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb13767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrissielok/Downloads/DATASCI_223/06-brainiac-chrissie331/helpers.py:183: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Visualize some training images to verify data loaded correctly\n",
    "plot_sample_images(X_train, y_train, CIFAR10_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc56b343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">786,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m786,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">820,874</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m820,874\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">820,874</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m820,874\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Build a Dense model using Sequential\n",
    "# Tip: call model_dense.summary() after building to verify your architecture\n",
    "# Requirements:\n",
    "#   - Input(shape=(32, 32, 3))\n",
    "#   - Flatten()\n",
    "#   - At least 2 Dense hidden layers with activation='relu'\n",
    "#   - Dropout after each hidden Dense layer\n",
    "#   - Dense(10, activation='softmax') as output\n",
    "  # replace with your Sequential mode\n",
    "model_dense = Sequential([\n",
    "    Input(shape=(32,32,3)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation = 'softmax')\n",
    "\n",
    "])\n",
    "model_dense.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52067ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_dense.compile(optimizer='adam',\n",
    "#                     loss='categorical_crossentropy',\n",
    "#                     metrics=['accuracy'])\n",
    "\n",
    "model_dense.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333c3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.2415 - loss: 2.0509 - val_accuracy: 0.3290 - val_loss: 1.8588\n",
      "Epoch 2/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2959 - loss: 1.9193 - val_accuracy: 0.3552 - val_loss: 1.8179\n",
      "Epoch 3/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3199 - loss: 1.8649 - val_accuracy: 0.3558 - val_loss: 1.7890\n",
      "Epoch 4/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3316 - loss: 1.8370 - val_accuracy: 0.3810 - val_loss: 1.7533\n",
      "Epoch 5/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3432 - loss: 1.8080 - val_accuracy: 0.3890 - val_loss: 1.7453\n",
      "Epoch 6/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3463 - loss: 1.7998 - val_accuracy: 0.3980 - val_loss: 1.7424\n",
      "Epoch 7/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.3489 - loss: 1.7906 - val_accuracy: 0.3930 - val_loss: 1.7320\n",
      "Epoch 8/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3570 - loss: 1.7723 - val_accuracy: 0.4068 - val_loss: 1.7019\n",
      "Epoch 9/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3585 - loss: 1.7658 - val_accuracy: 0.4172 - val_loss: 1.6761\n",
      "Epoch 10/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.3659 - loss: 1.7498 - val_accuracy: 0.4168 - val_loss: 1.6791\n",
      "Epoch 11/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.3668 - loss: 1.7466 - val_accuracy: 0.4254 - val_loss: 1.6561\n",
      "Epoch 12/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3673 - loss: 1.7388 - val_accuracy: 0.4078 - val_loss: 1.6792\n",
      "Epoch 13/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3678 - loss: 1.7393 - val_accuracy: 0.4118 - val_loss: 1.6857\n",
      "Epoch 14/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3711 - loss: 1.7299 - val_accuracy: 0.4186 - val_loss: 1.6636\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train with EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=3,\n",
    "#                            restore_best_weights=True)\n",
    "# history_dense = model_dense.fit(X_train, y_train,\n",
    "#                                 epochs=20, batch_size=128,\n",
    "#                                 validation_split=0.1,\n",
    "#                                 callbacks=[early_stop])\n",
    "# replace with your fit call\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 3,\n",
    "                           restore_best_weights=True)\n",
    "                           \n",
    "history_dense = model_dense.fit(X_train, y_train,\n",
    "                                epochs = 20, batch_size = 128,\n",
    "                                validation_split = 0.1,\n",
    "                                callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65f71e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense model test accuracy: 43.16%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# test_loss, test_acc = model_dense.evaluate(X_test, y_test, verbose=0)\n",
    "test_loss, test_acc = model_dense.evaluate(X_test, y_test, verbose=0) # replace\n",
    "print(f\"Dense model test accuracy: {test_acc:.2%}\")\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred = np.argmax(model_dense.predict(X_test, verbose=0), axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "y_pred = np.argmax(model_dense.predict(X_test, verbose=0), axis = 1)  # replace\n",
    "y_true = np.argmax(y_test, axis = 1)  # replace\n",
    "cm = confusion_matrix(y_true, y_pred)  # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6de654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrissielok/Downloads/DATASCI_223/06-brainiac-chrissie331/helpers.py:242: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Optional: visualize predictions and confusion matrix to diagnose issues\n",
    "plot_predictions(X_test, y_true, y_pred, CIFAR10_CLASSES)\n",
    "plot_confusion_matrix(y_true, y_pred, list(CIFAR10_CLASSES.values()),\n",
    "                      os.path.join(OUTPUT_DIR, \"part1_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b65a99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense accuracy: 0.4316\n",
      "Saved output/part1_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results = {\n",
    "    \"accuracy\": float(test_acc),\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part1_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(\"Saved output/part1_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4daa2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CNN on CIFAR-10\n",
    "\n",
    "**Task:** Build a CNN to classify the same CIFAR-10 images. Compare its accuracy\n",
    "to the Dense baseline from Part 1.\n",
    "\n",
    "CNNs use convolutional filters that slide across the image, detecting local\n",
    "patterns (edges, textures, shapes). This preserves spatial structure that\n",
    "Dense layers discard.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- At least 2 Conv2D + MaxPooling2D blocks\n",
    "- Flatten, then Dense hidden layer with Dropout\n",
    "- Output: Dense(10, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a124f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part 2: CNN on CIFAR-10\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPart 2: CNN on CIFAR-10\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Data is already loaded from Part 1 (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3605c597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m147,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,562</span> (654.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m167,562\u001b[0m (654.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,562</span> (654.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m167,562\u001b[0m (654.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Build a CNN model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(32, 32, 3))\n",
    "#   - At least 2 blocks of: Conv2D(filters, (3,3), activation='relu')\n",
    "#                            + MaxPooling2D((2,2))\n",
    "#   - Flatten()\n",
    "#   - Dense hidden layer with ReLU + Dropout\n",
    "#   - Dense(10, activation='softmax') as output\n",
    "# Tip: call model_cnn.summary() after building to check layer shapes and param counts\n",
    "# replace with your Sequential model\n",
    "model_cnn = Sequential([\n",
    "    Input(shape=(32,32,3)),\n",
    "\n",
    "    #Block 1: detect simple patterns (edges, textures)\n",
    "    Conv2D(32, (3,3), activation = 'relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    #Block 2: combine simple patterns into complex features\n",
    "    Conv2D(64, (3,3), activation = 'relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    #Classication head\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')\n",
    "\n",
    "])  \n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34c9b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# model_cnn.compile(optimizer='adam',\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "model_cnn.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a565d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 39ms/step - accuracy: 0.4256 - loss: 1.5855 - val_accuracy: 0.5350 - val_loss: 1.3041\n",
      "Epoch 2/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 40ms/step - accuracy: 0.5398 - loss: 1.2880 - val_accuracy: 0.6082 - val_loss: 1.1385\n",
      "Epoch 3/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 39ms/step - accuracy: 0.5863 - loss: 1.1624 - val_accuracy: 0.6414 - val_loss: 1.0273\n",
      "Epoch 4/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 38ms/step - accuracy: 0.6200 - loss: 1.0806 - val_accuracy: 0.6592 - val_loss: 0.9961\n",
      "Epoch 5/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 39ms/step - accuracy: 0.6395 - loss: 1.0239 - val_accuracy: 0.6702 - val_loss: 0.9332\n",
      "Epoch 6/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 37ms/step - accuracy: 0.6550 - loss: 0.9825 - val_accuracy: 0.6668 - val_loss: 0.9398\n",
      "Epoch 7/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 152ms/step - accuracy: 0.6706 - loss: 0.9422 - val_accuracy: 0.6758 - val_loss: 0.9172\n",
      "Epoch 8/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 39ms/step - accuracy: 0.6812 - loss: 0.9104 - val_accuracy: 0.7048 - val_loss: 0.8466\n",
      "Epoch 9/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 40ms/step - accuracy: 0.6906 - loss: 0.8854 - val_accuracy: 0.7026 - val_loss: 0.8646\n",
      "Epoch 10/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 38ms/step - accuracy: 0.7008 - loss: 0.8520 - val_accuracy: 0.7020 - val_loss: 0.8648\n",
      "Epoch 11/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 42ms/step - accuracy: 0.7109 - loss: 0.8294 - val_accuracy: 0.7040 - val_loss: 0.8569\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train with EarlyStopping and ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3,\n",
    "                  restore_best_weights=True),\n",
    "    ModelCheckpoint('output/best_cnn.keras',\n",
    "                   save_best_only=True, monitor='val_accuracy'),\n",
    "]\n",
    "# history_cnn = model_cnn.fit(X_train, y_train,\n",
    "#                             epochs=15, batch_size=64,\n",
    "#                             validation_split=0.1,\n",
    "#                             callbacks=callbacks)\n",
    " # replace with your fit call\n",
    "history_cnn = model_cnn.fit(X_train, y_train,\n",
    "                            epochs= 15, batch_size = 64,\n",
    "                            validation_split = 0.1,\n",
    "                            callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccd07834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "plot_training_history(history_cnn,\n",
    "                      os.path.join(OUTPUT_DIR, \"part2_training_history.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1acb0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# cnn_loss, cnn_acc = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "cnn_loss, cnn_acc = model_cnn.evaluate(X_test, y_test, verbose=0)  # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred_cnn = np.argmax(model_cnn.predict(X_test, verbose=0), axis=1)\n",
    "# y_true_cnn = np.argmax(y_test, axis=1)\n",
    "# cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn)\n",
    "y_pred_cnn = np.argmax(model_cnn.predict(X_test, verbose =0), axis =1)  # replace\n",
    "y_true_cnn = np.argmax(y_test, axis =1) # replace\n",
    "cm_cnn = confusion_matrix(y_true_cnn, y_pred_cnn) # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d455628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrissielok/Downloads/DATASCI_223/06-brainiac-chrissie331/helpers.py:242: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Optional: visualize predictions and confusion matrix to diagnose issues\n",
    "plot_predictions(X_test, y_true_cnn, y_pred_cnn, CIFAR10_CLASSES)\n",
    "plot_confusion_matrix(y_true_cnn, y_pred_cnn, list(CIFAR10_CLASSES.values()),\n",
    "                      os.path.join(OUTPUT_DIR, \"part2_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74ee7f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN accuracy:   0.6934\n",
      "Dense accuracy: 0.4316\n",
      "Improvement:    +0.2618\n",
      "Saved output/part2_results.json and output/part2_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_cnn = {\n",
    "    \"accuracy\": float(cnn_acc),\n",
    "    \"confusion_matrix\": cm_cnn.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part2_results.json\"), \"w\") as f:\n",
    "    json.dump(results_cnn, f, indent=2)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\"model\": \"Dense\", \"accuracy\": float(test_acc)},\n",
    "    {\"model\": \"CNN\", \"accuracy\": float(cnn_acc)},\n",
    "])\n",
    "comparison.to_csv(os.path.join(OUTPUT_DIR, \"part2_comparison.csv\"), index=False)\n",
    "\n",
    "print(f\"CNN accuracy:   {cnn_acc:.4f}\")\n",
    "print(f\"Dense accuracy: {test_acc:.4f}\")\n",
    "print(f\"Improvement:    {cnn_acc - test_acc:+.4f}\")\n",
    "print(\"Saved output/part2_results.json and output/part2_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f949ce7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: LSTM on ECG5000\n",
    "\n",
    "**Task:** Build an LSTM to classify heartbeat recordings.\n",
    "\n",
    "ECG5000 contains 5,000 heartbeat recordings — each is 140 time steps of voltage\n",
    "measurements, classified into 5 types (Normal, Supraventricular, Premature\n",
    "Ventricular, Fusion, Unknown). This is sequential data where order matters,\n",
    "making it a natural fit for recurrent networks.\n",
    "\n",
    "**Architecture requirements:**\n",
    "- LSTM layer (any reasonable number of units)\n",
    "- Dropout for regularization\n",
    "- Dense output with softmax (5 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d320a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part 3: LSTM on ECG5000\n",
      "----------------------------------------\n",
      "Train: (4000, 140, 1), Test: (1000, 140, 1)\n",
      "Classes: ['Normal', 'Supraventricular', 'Premature Ventricular', 'Fusion', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPart 3: LSTM on ECG5000\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load ECG data (already shaped for RNN input)\n",
    "X_train_ecg, y_train_ecg, X_test_ecg, y_test_ecg = load_ecg5000()\n",
    "print(f\"Train: {X_train_ecg.shape}, Test: {X_test_ecg.shape}\")\n",
    "print(f\"Classes: {list(ECG_CLASSES.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc6c0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrissielok/Downloads/DATASCI_223/06-brainiac-chrissie331/helpers.py:211: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Visualize ECG traces to understand the data\n",
    "plot_ecg_traces(X_train_ecg, y_train_ecg, ECG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "789dec0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,221</span> (67.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,221\u001b[0m (67.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,221</span> (67.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,221\u001b[0m (67.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Build an LSTM model using Sequential\n",
    "# Requirements:\n",
    "#   - Input(shape=(140, 1))\n",
    "#   - LSTM layer (e.g., 64 units)\n",
    "#   - Dropout\n",
    "#   - Dense(5, activation='softmax')\n",
    "# Tip: call model_lstm.summary() after building to verify your architecture\n",
    "# replace with your Sequential model\n",
    "model_lstm = Sequential([\n",
    "    Input(shape = (140,1)),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation = 'softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model_lstm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a0f4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "model_lstm.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4a2b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.8828 - loss: 0.5265 - val_accuracy: 0.8875 - val_loss: 0.3605\n",
      "Epoch 2/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9314 - loss: 0.2565 - val_accuracy: 0.9175 - val_loss: 0.3100\n",
      "Epoch 3/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9386 - loss: 0.2335 - val_accuracy: 0.9150 - val_loss: 0.3057\n",
      "Epoch 4/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9408 - loss: 0.2231 - val_accuracy: 0.9125 - val_loss: 0.2947\n",
      "Epoch 5/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.9406 - loss: 0.2102 - val_accuracy: 0.9150 - val_loss: 0.2903\n",
      "Epoch 6/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9428 - loss: 0.2036 - val_accuracy: 0.9200 - val_loss: 0.2743\n",
      "Epoch 7/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.9436 - loss: 0.1995 - val_accuracy: 0.9275 - val_loss: 0.2745\n",
      "Epoch 8/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9464 - loss: 0.1952 - val_accuracy: 0.9250 - val_loss: 0.2531\n",
      "Epoch 9/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9481 - loss: 0.1844 - val_accuracy: 0.9275 - val_loss: 0.2583\n",
      "Epoch 10/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9464 - loss: 0.1833 - val_accuracy: 0.9225 - val_loss: 0.2558\n",
      "Epoch 11/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.9447 - loss: 0.1844 - val_accuracy: 0.9250 - val_loss: 0.2499\n",
      "Epoch 12/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9472 - loss: 0.1797 - val_accuracy: 0.9225 - val_loss: 0.2504\n",
      "Epoch 13/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.9458 - loss: 0.1807 - val_accuracy: 0.9200 - val_loss: 0.2272\n",
      "Epoch 14/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9478 - loss: 0.1709 - val_accuracy: 0.9225 - val_loss: 0.2358\n",
      "Epoch 15/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9450 - loss: 0.1805 - val_accuracy: 0.9250 - val_loss: 0.2509\n",
      "Epoch 16/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.9492 - loss: 0.1729 - val_accuracy: 0.9300 - val_loss: 0.2294\n",
      "Epoch 17/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9478 - loss: 0.1696 - val_accuracy: 0.9250 - val_loss: 0.2516\n",
      "Epoch 18/30\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9494 - loss: 0.1686 - val_accuracy: 0.9200 - val_loss: 0.2320\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train with EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5,\n",
    "                          restore_best_weights=True)\n",
    "# history_lstm = model_lstm.fit(X_train_ecg, y_train_ecg,\n",
    "#                               epochs=30, batch_size=32,\n",
    "#                               validation_split=0.1,\n",
    "#                               callbacks=[early_stop])\n",
    "history_lstm = model_lstm.fit(X_train_ecg, y_train_ecg,\n",
    "                              epochs = 30, batch_size = 32,\n",
    "                              validation_split = 0.1,\n",
    "                              callbacks = [early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a28a9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "plot_training_history(history_lstm,\n",
    "                      os.path.join(OUTPUT_DIR, \"part3_training_history.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97b28180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate on test set\n",
    "# lstm_loss, lstm_acc = model_lstm.evaluate(X_test_ecg, y_test_ecg, verbose=0)\n",
    "lstm_loss, lstm_acc = model_lstm.evaluate(X_test_ecg, y_test_ecg, verbose = 0) # replace\n",
    "\n",
    "# TODO: Generate predictions and confusion matrix\n",
    "# y_pred_ecg = np.argmax(model_lstm.predict(X_test_ecg, verbose=0), axis=1)\n",
    "# y_true_ecg = np.argmax(y_test_ecg, axis=1)\n",
    "# cm_ecg = confusion_matrix(y_true_ecg, y_pred_ecg)\n",
    "y_pred_ecg = np.argmax(model_lstm.predict(X_test_ecg, verbose = 0), axis = 1) # replace\n",
    "y_true_ecg = np.argmax(y_test_ecg, axis = 1)  # replace\n",
    "cm_ecg = confusion_matrix(y_true_ecg, y_pred_ecg) # replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31a5a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: visualize confusion matrix to see which heartbeat types are confused\n",
    "plot_confusion_matrix(y_true_ecg, y_pred_ecg, list(ECG_CLASSES.values()),\n",
    "                      os.path.join(OUTPUT_DIR, \"part3_confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b74ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM accuracy: 0.9320\n",
      "Saved output/part3_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results (do not modify this cell)\n",
    "results_ecg = {\n",
    "    \"accuracy\": float(lstm_acc),\n",
    "    \"confusion_matrix\": cm_ecg.tolist(),\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"part3_results.json\"), \"w\") as f:\n",
    "    json.dump(results_ecg, f, indent=2)\n",
    "\n",
    "print(f\"LSTM accuracy: {lstm_acc:.4f}\")\n",
    "print(\"Saved output/part3_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69849039",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d00802a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All parts complete!\n",
      "Run 'pytest .github/tests/ -v' in your terminal to check your work.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAll parts complete!\")\n",
    "print(\"Run 'pytest .github/tests/ -v' in your terminal to check your work.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
